\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Yelp Recommendations}

\author{
Gavriel Adler\\
Carnegie Mellon University\\
{\tt\small gya@andrew.cmu.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Spencer Barton\\
Carnegie Mellon University\\
{\tt\small sebarton@andrew.cmu.edu}
\and
Fridtjof Melle\\
Carnegie Mellon University\\
{\tt\small fmelle@andrew.cmu.edu}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   When looking for somewhere to eat, people often read online reviews of restaurants they have not visited themselves. One of the most common websites that aggregates user reviews is \url{http://www.yelp.com}. Using machine learning techniques, we aimed make this process simpler by giving users specific restaurant recommendations, replacing their time spent looking through many possible places to eat, turning down many or most of them, with a small subset of restaurants the user is likely to enjoy based on the reviews of similar users.

   
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

\subsection{The Problem}
\url{http://www.yelp.com} is a popular destination for people looking to find out what other people think of restaurants, coffee shops, and other food establishments in their area. Often people make decisions on where to eat based on the reviews other yelp members give to restaurants they're considering. While this is more useful than having no information about the restaurant at all, someone looking for a recommendation is bound to the opinions of strangers, who perhaps have very different tastes in food. 
\subsection{The Solution}
Our solution is to fix this problem by giving a person personalized recommendations. Based on the person's past reviews, we aim to find a subset of \textit{Yelp} users with similar taste and guess the scores that the given person would give to restaurants he or she has not yet visited. This allows the person to try a new restaurant with a greater sense of security that he or she will enjoy the experience and not waste money. \cite{Alpher02}

\section{Data Set}
\subsection{Overview}
\textit{Yelp} holds a massive amount of data to their disposal based on everything that users provide in terms of personal information, business information and everything they put into their reviews. For our purpose \textit{Yelp} provides a subset of this based on a specific region or city, generated with the same attributes as the real world data, which for our case is Phoenix, Arizona. This provides us with a total of 14303 restaurants and 1.2M reviews, all connected to Phoenix through around 250000 users. The data is originally compiled JSON, which we have expanded to operate on, and then convert to a matrix-based CSV-format for classification and prediction. The scripts which do this can easily be adapted to load in more or less data as we proceed with the project.

\subsection{Users}
In order to generate a user characterizing model we were inclined to extract all the elite users as they contain the most data and will be the easiest to map for interests and taste. These users count a total of 20045 individuals, all with an average of 200 reviews each. This gives us a good basis to develop a model. In addition we have randomly extracted 2014 sample users not contained within the training data, to test our algorithm on, as well as the top 50 reviewers from the elite users to test the pipeline on. All users are in the same reduced format, only containing the parameters we deem necessary for characterizing the particular users whereas removed attributes primarily include \textit{friends}. Below is an example of user-specific data we will use as basis for our models.

\begin{verbatim}
	{
        "average_stars": 3.65,
        "compliments": {
            "cool": 16,
            "funny": 5,
            "hot": 8,
            "more": 1,
            "note": 3,
            "plain": 9,
            "profile": 1,
            "writer": 4
        },
        "elite": [
            2013,
            2014
        ],
        "fans": 7,
        "name": "Lene",
        "review_count": 214,
        "user_id": "WvhiRlcy-XYwiCof",
        "votes": {
            "cool": 110,
            "funny": 56,
            "useful": 274
        },
        "yelping_since": "2010-10"
    }
\end{verbatim}

\subsection{Restaurants}
As \textit{Yelp} does not limit themselves to restaurants, neither does the original data set. Extracting these was the first part of our extraction. Furthermore, the restaurants contains a lot of information that we wouldn't find particularly interesting for our purposes and subsequently removed attributes as \textit{address}, \textit{hours}, \textit{neighborhoods}, geographical coordinates and general attributes such as \textit{Wi-fi}, \textit{Ambiance}, \textit{Noise level} and \textit{Attire}. We finally end up with a set of 14303 restaurants whereas one example of information we will use is detailed below.

\begin{verbatim}
	{
	    "business_id": "8Jg4S5r79dh",
	    "categories": [
	        "Pizza",
	        "Restaurants"
	    ],
	    "city": "Phoenix",
	    "name": "Mellow Mushroom",
	    "review_count": 62,
	    "average_stars": 3.5,
	    "state": "AZ"
	}
\end{verbatim}

\subsection{Reviews}
While users and restaurants are necessary input information to structure our data and our results, the reviews are the backbone of our predictions and binds all of the data together. With a total of 1.2M reviews we chose to look away from the actual review text for now, as feature generation through analysis of this would become significant in our work progress, leaving us with a following structure of our reviews.

\begin{verbatim}
	{
	    "business_id": "HD_D2LTNTL6EXmvH",
	    "date": "2012-02-19",
	    "review_id": "3vZLrrZ6-kvTO5Q7",
	    "stars": 5,
	    "user_id": "t6GmgDZNeaTnj75NT",
	    "votes": {
	        "cool": 2,
	        "funny": 2,
	        "useful": 2
	    }
	}
\end{verbatim}

\section{Algorithm Overivew}
\subsection{The Pipeline}
\begin{figure}[t]
\begin{center}
\fbox{\rule{0pt}{2in}
   \includegraphics[width=0.8\linewidth]{WorkFlow.png}}
\end{center}
   \caption{A workflow diagram of our pipeline.}
\label{fig:long}
\label{fig:onecol}
\end{figure}

Our pipeline takes in a given user, and outputs a restaurant recommendation. In order to do this we first create a feature vector for the person, and find determine the most similar users based on these features. We then see how these similar users rated restaurants the user has not been to, and thus evaluate how the user would rate those restaurants. Finally, the restaurant with the highest expected rating is returned to the user.

\section{What We Have Done}
\subsection{Parsing the Data}
Even with the reduced data set, while establishing the pipeline we wanted to work with an even smaller set to better visualize and evaluate the input and output. We therefore currently only use the data for the very top 50 elite users, and all the restaurants they have visited, as well as their reviews of them, and their personal data.
\subsection{Making User Vectors and Finding Similar Users}
Our solution creates a feature vector of each user and uses the K Nearest Neighbors algorithm to sort the feature vectors and find K users closest to the person based on the feature vector.
\\[0.5em]
\indent Right now our user vectors are based on the user's \textit{Yelp} profiles. Yelp user reviews can be rated by other users as "funny", "useful", and "cool". Users can also compliment other users in many ways. We vectorize all of a users ratings and complements, as well as append the user \textit{Yelp} statistics (fans, average review rating, and number of reviews). This feature vector gives us an idea of how other users view this user in the \textit{Yelp} community. This feature vector was a quick way to create a feature vector that we could use and test in our pipeline, in the future we plan to add food and restaurant-specific features. To find similar usres, we simply run KNN for a single user feature vector on the entire set of user feature vectors. Modifying the feature vector is one of the key steps we plan to work on in the next half of the project.
\subsection{Guessing User Reviews}
Our solution takes a weighted average of the reviews from those users for every restaurant the person has not visited to evaluate how that person would rate those restaurants.
\\[0.5em]
\indent Right now, to guess a user review, we take two things into account: the ratings the similar users rated a restaurant and the average rating of the restaurant. We weight each by a half to guess how a user would rate a restaurant.
\subsection{Implementation}
Our code is implemented in Python's PANDAS module. Coding in Python allows us to rapidly prototype and get things working in the short amount of time we have to do the project. PANDAS, being strictly typed and implemented in C, speeds of computation time considerably and allows us to run our code on a much larger dataset. The code is visible at \url{https://github.com/sbarton272/PatRec}.

\section{What We Plan to Do}
Our current progress has aimed at establishing a pipeline that we believe have the potential of performing decent restaurant prediction given the right feature selection and evaluation. Although at this point the information we use to establish feature vectors and perform predictions are rather simple and serve in getting our system up, before we complicate with extensive analysis and feature selection. In order to perform a proper restaurant predictions and give good recommendations we will need to combine all the data we have to map the users more completely in terms of taste.

\subsection{Feature selection and dimensionality reduction}
Currently looking only at user-specific data for development of feature vectors we seek to progressivly focus more and more on their reviews. With the data visualized previously we should by connecting all the users to their reviews be able to map the individual users taste in terms what types of restaurants generally visited. 
\\[.5em]
\indent In a first time, we will seek to establish more advanced user vectors, including as much information as possible, before we can start statistically evaluating which features play the most signifcant role. We seek to explore this using techniques as LDA and PCA, comparing the results with the existing complete user vectors.

\subsection{Advanced prediction model based on similar users}

\subsection{Validation of output}

\subsection{Evaluation of classifier: Implement generative models}
Our current classifier, the KNN, is of the Deterministic Association type, making no assumptions of data distribution or correlation of any kind. This leaves a big room of improvement as our data contains unused information that we can take into equation. Rather than just deterministically sorting users based on numerical values, can further cluster and develop user-characterizing models based on taste. This edge especially relates to the fact that every restaurant is characterized by a set of labels such as \textit{Mexican}, \textit{Pizza}, \textit{American} among others that permits us to map a users taste based on general visitation and following reviews. Not only can this play a part in the development of similarity, but also help further weight the restaurant valuations and predictions in the following evaluation. We currently imagine using techniques such as Naïve Bayes with possible follow-up by a GMM variation.

\section{Challenges and Potential Issues}
\subsection{Geograpichal restrictions}
As mentioned our extracted data set contains users, restaurants and reviews somehow related to Phoenix, AZ. Although, this does not mean that every user, restaurant or review is directly connected this region. If a user has done one review of one restaurant in Phoenix, all his other reviews and effectively the corresponding restaurants is included in the data set. For now we have looked away from geographical locations, in order to have our algorithm give the best possible recommendation regardless of its location, but this is something we might have to look into later.

%uncomment and add \cite{}'s for bilbiography. fill in egbib.bib file
{\small
\bibliographystyle{ieee}
\bibliography{egbib}}


\end{document}
