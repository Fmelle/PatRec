\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Yelp Recommendations}

\author{
Gavriel Adler\\
Carnegie Mellon University\\
{\tt\small gya@andrew.cmu.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Spencer Barton\\
Carnegie Mellon University\\
{\tt\small sebarton@andrew.cmu.edu}
\and
Fridtjof Melle\\
Carnegie Mellon University\\
{\tt\small fmelle@andrew.cmu.edu}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   When looking for somewhere to eat, people often read online reviews of restaurants they have not visited themselves. One of the most common websites that aggregates user reviews is \url{http://www.yelp.com}. Using machine learning techniques, we aimed make this process simpler by giving users specific restaurant recommendations, replacing their time spent looking through many possible places to eat, turning down many or most of them, with a small subset of restaurants the user is likely to enjoy based on the reviews of similar users.

   
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

\subsection{The Problem}
\url{http://www.yelp.com} is a popular destination for people looking to find out what other people think of restaurants, coffee shops, and other food establishments in their area. Often people make decisions on where to eat based on the reviews other yelp members give to restaurants they're considering. While this is more useful than having no information about the restaurant at all, someone looking for a recommendation is bound to the opinions of strangers, who perhaps have very different tastes in food. 
\subsection{The Solution}
Our solution is to fix this problem by giving a person personalized recommendations. Based on the person's past reviews, we aim to find a subset of \textit{Yelp} users with similar taste and guess the scores that the given person would give to restaurants he or she has not yet visited. This allows the person to try a new restaurant with a greater sense of security that he or she will enjoy the experience and not waste money. \cite{Alpher02}

\section{Data Set}
\subsection{Overview}
\textit{Yelp} holds a massive amount of data to their disposal based on everything that users provide in terms of personal information, business information and everything they put into their reviews. For our purpose \textit{Yelp} provides a subset of this based on a specific region or city, generated with the same attributes as the real world data, which for our case is Phoenix, Arizona. This provides us with a total of 14303 restaurants and 1.2M reviews, all connected to Phoenix through around 250000 users. The data is originally compiled JSON, which we have expanded to operate on, and then convert to a matrix-based CSV-format for classification and prediction. The scripts which do this can easily be adapted to load in more or less data as we proceed with the project.

\subsection{Users}
In order to generate a user characterizing model we were inclined to extract all the elite users as they contain the most data and will be the easiest to map for interests and taste. These users count a total of 20045 individuals, all with an average of 200 reviews each. This gives us a good basis to develop a model. In addition we have randomly extracted 2014 sample users not contained within the training data, to test our algorithm on, as well as the top 50 reviewers from the elite users to test the pipeline on. All users are in the same reduced format, only containing the parameters we deem necessary for characterizing the particular users whereas removed attributes primarily include \textit{friends}. Below is an example of user-specific data we will use as basis for our models.

\begin{verbatim}
	{
        "average_stars": 3.65,
        "compliments": {
            "cool": 16,
            "funny": 5,
            "hot": 8,
            "more": 1,
            "note": 3,
            "plain": 9,
            "profile": 1,
            "writer": 4
        },
        "elite": [
            2013,
            2014
        ],
        "fans": 7,
        "name": "Lene",
        "review_count": 214,
        "user_id": "WvhiRlcyEiy-XYwiCofzdg",
        "votes": {
            "cool": 110,
            "funny": 56,
            "useful": 274
        },
        "yelping_since": "2010-10"
    }
\end{verbatim}

\subsection{Restaurants}
As \textit{Yelp} does not limit themselves to restaurants, neither does the original data set. Extracting these was the first part of our extraction. Furthermore, the restaurants contains a lot of information that we wouldn't find particularly interesting for our purposes and subsequently removed attributes as \textit{address}, \textit{hours}, \textit{neighborhoods}, geographical coordinates and general attributes such as \textit{Wi-fi}, \textit{Ambiance}, \textit{Noise level} and \textit{Attire}. We finally end up with a set of 14303 restaurants whereas one example of information we will use is detailed below.

\begin{verbatim}
	{
	    "business_id": "8Jg4S5r79dh",
	    "categories": [
	        "Pizza",
	        "Restaurants"
	    ],
	    "city": "Phoenix",
	    "name": "Mellow Mushroom",
	    "review_count": 62,
	    "average_stars": 3.5,
	    "state": "AZ"
	}
\end{verbatim}

\subsection{Reviews}
While users and restaurants are necessary input information to structure our data and our results, the reviews are the backbone of our predictions and binds all of the data together. With a total of 1.2M reviews we chose to look away from the actual review text for now, as feature generation through analysis of this would become significant in our work progress, leaving us with a following structure of our reviews.

\begin{verbatim}
	{
	    "business_id": "HD_D2LTNTL6EXmvHF6x1qg",
	    "date": "2012-02-19",
	    "review_id": "3vZLrrZ6aVt-kvTO5Q79pQ",
	    "stars": 5,
	    "user_id": "t6GmgDZNeaTnj75NTRWc2w",
	    "votes": {
	        "cool": 2,
	        "funny": 2,
	        "useful": 2
	    }
	}
\end{verbatim}

\section{Algorithm Overivew}
\subsection{The Pipeline}
\begin{figure}[t]
\begin{center}
\fbox{\rule{0pt}{2in}
   \includegraphics[width=0.8\linewidth]{WorkFlow.png}}
\end{center}
   \caption{A workflow diagram of our pipeline.}
\label{fig:long}
\label{fig:onecol}
\end{figure}

Our pipeline takes in a given user, and outputs a restaurant recommendation. In order to do this we first create a feature vector for the person, and find determine the most similar users based on these features. We then see how these similar users rated restaurants the user has not been to, and thus evaluate how the user would rate those restaurants. Finally, the restaurant with the highest expected rating is returned to the user.

\section{What We Have Done}
\subsection{Parsing the Data}
Even with the reduced data set, while establishing the pipeline we wanted to work with an even smaller set to visualize the input and output. We therefore took the data for the very top 50 elite users, and all the restaurants they have visited, as well as their reviews of them, and their personal data.
\subsection{Making User Vectors and Finding Similar Users}
Our solution creates a feature vector of each user and uses the K Nearest Neighbors algorithm to sort the feature vectors and find K users closest to the person based on the feature vector. We then take a weighted average of the reviews from those users for every restaurant the person has not visited to guess how that person would rate those restaurants.
\\[0.5em]
\indent Right now our user vectors are based on the user's \textit{Yelp} profiles. Yelp user reviews can be rated by other users as "funny", "useful", and "cool". Users can also compliment other users in many ways. We vectorize all of a users ratings and complements, as well as append the user \textit{Yelp} statistics (fans, average review rating, and number of reviews). This feature vector gives us an idea of how other users view this user in the \textit{Yelp} community. This feature vector was a quick way to create a feature vector that we could use and test in our pipeline, in the future we plan to add food and restaurant-specific features. To find similar usres, we simply run KNN for a single user feature vector on the entire set of user feature vectors. Modifying the feature vector is one of the key steps we plan to work on in the next half of the project.
\subsection{Guessing User Reviews}
Right now, to guess a user review, we take two things into account: the ratings a user's similar users rated a restaurant and the average rating of the restaurant. We weight each by a half to guess how a user would rate a restaurant.
\subsection{Implementation}
Our code is implemented in Python's PANDAS module. Coding in Python allows us to rapidly prototype and get things working in the short amount of time we have to do the project. PANDAS, being strictly typed and implemented in C, speeds of computation time considerably and allows us to run our code on a much larger dataset. The code is visible at \url{https://github.com/sbarton272/PatRec}.

\section{What We Plan to Do}

\section{Challenges and Potential Issues}
\subsection{Geograpichal restrictions}
As mentioned our extracted data set contains users, restaurants and reviews somehow related to Phoenix, AZ. Although, this does not mean that every user, restaurant or review is directly connected this region. If a user has done one review of one restaurant in Phoenix, all his other reviews and effectively the corresponding restaurants is included in the data set. For now we have looked away from geographical locations, in order to have our algorithm give the best possible recommendation regardless of its location, but this is something we might have to look into later.

\subsection{Duplications of reviews}
rofl

%uncomment and add \cite{}'s for bilbiography. fill in egbib.bib file
{\small
\bibliographystyle{ieee}
\bibliography{egbib}}


\end{document}
